apiVersion: v1
kind: Service
metadata:
  name: heavyai
  labels:
    app: heavyai
spec:
  ports:
    - port: 6273
      name: heavyai
      protocol: TCP
      targetPort: 6273
  selector:
    app: heavyai
  clusterIP: None
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: heavyai
  name: heavyai
spec:
  port:
    targetPort: http
#  tls:
#    insecureEdgeTerminationPolicy: Redirect
#    termination: reencrypt
  to:
    kind: Service
    name: heavyai
    weight: 100
---
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: heavyai
  labels:
    app: heavyai
spec:
  selector:
    matchLabels:
      app: heavyai
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: heavyai
    spec:
      nodeSelector:
        feature.node.kubernetes.io/pci-10de.present: 'true'
#      affinity:
#        nodeAffinity:
#          requiredDuringSchedulingIgnoredDuringExecution:
#            nodeSelectorTerms:
#            - matchExpressions:
#              - key: openshift.com/gpu-accelerator
#                operator: Exists
      containers:
      - image: docker.io/heavyai/heavyai-ee-cuda:latest
        imagePullPolicy: Always
        name: heavyai-ee-cuda-latest
        env:
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: compute,utility,graphics
        - name: NVIDIA_VISIBLE_DEVICES
          value: all
        ports:
        - containerPort: 6273
          name: heavyai
        resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
        volumeMounts:
        - name: heavyai-persistent-storage
          mountPath: /heavyai-storage
      volumes:
      - name: heavyai-persistent-storage
        persistentVolumeClaim:
          claimName: heavyai-pv-claim
