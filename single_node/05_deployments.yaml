apiVersion: v1
kind: Service
metadata:
  name: heavyai
  labels:
    app: heavyai
spec:
  ports:
    - port: 6273
      name: heavyai
      protocol: TCP
      targetPort: 6273
  selector:
    app: heavyai
  clusterIP: None
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: heavyai
  name: heavyai
spec:
  port:
    targetPort: heavyai
  to:
    kind: Service
    name: heavyai
    weight: 100
  wildcardPolicy: None
---
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: heavyai
  labels:
    app: heavyai
spec:
  selector:
    matchLabels:
      app: heavyai
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: heavyai
    spec:
      nodeSelector:
        feature.node.kubernetes.io/pci-10de.present: 'true'
      containers:
      - image: docker.io/heavyai/heavyai-ee-cuda:latest
        imagePullPolicy: Always
        name: heavyai-ee-cuda-latest
        env:
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: compute,utility,graphics
        - name: NVIDIA_VISIBLE_DEVICES
          value: all
        ports:
        - containerPort: 6273
          name: heavyai
        resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
        volumeMounts:
          - name: storage
            mountPath: /heavyai-storage
            subPath: heavyai-storage
          - name: heavyai
            mountPath: /var/lib/heavyai
          - name: config
            mountPath: /var/lib/heavyai/heavy.conf
            subPath: heavy.conf
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: heavyai-data
      - name: heavyai
        persistentVolumeClaim:
          claimName: heavydb
      - name: config
        configMap:
          name: heavy-config
          defaultMode: 420

